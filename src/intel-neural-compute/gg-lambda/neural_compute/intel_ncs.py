# realsense-simple.py
#
# TBA  
#
# Author: Dean Colcott - https://www.linkedin.com/in/deancolcott/
#
# Cerdit: Intel OpenVino pPthon examples
#

from __future__ import print_function
import sys
import os
import cv2
import numpy as np
import logging
from openvino.inference_engine import IECore
from argparse import ArgumentParser, SUPPRESS

# If running lambda as non-containerised GreenGrass then prefix any resource paths with AWS_GG_RESOURCE_PREFIX
ML_MODEL_BASE_PATH = "{}{}".format(os.getenv("AWS_GG_RESOURCE_PREFIX"), "/ml/od/")

# Just for dev, manualluy rest the model path
ML_MODEL_BASE_PATH = "../intel-models"
ML_MODEL_NAME = 'face-detection-adas-0001'

DEVICE = "MYRIAD"   # Specify making inference on NCS MYRIAD processor

IMAGE_FILE = "faces01.jpeg"

# Config the logger.
log = logging.getLogger(__name__)
logging.basicConfig(format="%(asctime)s - %(name)s - [%(levelname)s] - %(message)s", stream=sys.stdout, level=logging.INFO)

class IntelNcs():
    """
    Interact with the Intel Neural Compute Stick2
    """

    def __init__(self):

        # --------------------------- 1. Read IR Generated by ModelOptimizer (.xml and .bin files) ------------
        log.info("Loading Intel Compute Stick Inference Engine")
        ie = IECore()
        model_xml = os.path.join(ML_MODEL_BASE_PATH, ML_MODEL_NAME) +'.xml'
        model_bin = os.path.join(ML_MODEL_BASE_PATH, ML_MODEL_NAME) +'.bin'
        log.info("Loading network files:\n\t{}\n\t{}".format(model_xml, model_bin))
        net = ie.read_network(model=model_xml, weights=model_bin)
        # -----------------------------------------------------------------------------------------------------

        # ------------- 2. Load Plugin for inference engine and extensions library if specified --------------
        log.info("Device info:")
        versions = ie.get_versions(DEVICE)
        print("{}{}".format(" " * 8, DEVICE))
        print("{}MKLDNNPlugin version ......... {}.{}".format(" " * 8, versions[DEVICE].major,
                                                            versions[DEVICE].minor))
        print("{}Build ........... {}".format(" " * 8, versions[DEVICE].build_number))

        # -----------------------------------------------------------------------------------------------------

        # --------------------------- 3. Read and preprocess input --------------------------------------------

        print("inputs number: " + str(len(net.input_info.keys())))

        for input_key in net.input_info:
            print("input shape: " + str(net.input_info[input_key].input_data.shape))
            print("input key: " + input_key)
            if len(net.input_info[input_key].input_data.layout) == 4:
                n, c, h, w = net.input_info[input_key].input_data.shape

        images = np.ndarray(shape=(n, c, h, w))
        images_hw = []

        image = cv2.imread(IMAGE_FILE)
        ih, iw = image.shape[:-1]
        images_hw.append((ih, iw))
        log.info("File was added: {}".format(IMAGE_FILE))
        if (ih, iw) != (h, w):
            log.warning("Image {} is resized from {} to {}".format(IMAGE_FILE, image.shape[:-1], (h, w)))
            image = cv2.resize(image, (w, h))
        image = image.transpose((2, 0, 1))  # Change data layout from HWC to CHW
        images[0] = image
        
        # -----------------------------------------------------------------------------------------------------

        # --------------------------- 4. Configure input & output ---------------------------------------------
        # --------------------------- Prepare input blobs -----------------------------------------------------
        log.info("Preparing input blobs")
        assert (len(net.input_info.keys()) == 1 or len(
            net.input_info.keys()) == 2), "Sample supports topologies only with 1 or 2 inputs"
        out_blob = next(iter(net.outputs))
        input_name, input_info_name = "", ""

        for input_key in net.input_info:
            if len(net.input_info[input_key].layout) == 4:
                input_name = input_key
                log.info("Batch size is {}".format(net.batch_size))
                net.input_info[input_key].precision = 'U8'
            elif len(net.input_info[input_key].layout) == 2:
                input_info_name = input_key
                net.input_info[input_key].precision = 'FP32'
                if net.input_info[input_key].input_data.shape[1] != 3 and net.input_info[input_key].input_data.shape[1] != 6 or \
                    net.input_info[input_key].input_data.shape[0] != 1:
                    log.error('Invalid input info. Should be 3 or 6 values length.')

        data = {}
        data[input_name] = images

        if input_info_name != "":
            infos = np.ndarray(shape=(n, c), dtype=float)
            for i in range(n):
                infos[i, 0] = h
                infos[i, 1] = w
                infos[i, 2] = 1.0
            data[input_info_name] = infos


        # --------------------------- Prepare output blobs ----------------------------------------------------
        log.info('Preparing output blobs')

        output_name, output_info = "", net.outputs[next(iter(net.outputs.keys()))]
        for output_key in net.outputs:
            if net.layers[output_key].type == "DetectionOutput":
                output_name, output_info = output_key, net.outputs[output_key]

        if output_name == "":
            log.error("Can't find a DetectionOutput layer in the topology")

        output_dims = output_info.shape
        if len(output_dims) != 4:
            log.error("Incorrect output dimensions for SSD model")
        max_proposal_count, object_size = output_dims[2], output_dims[3]

        if object_size != 7:
            log.error("Output item should have 7 as a last dimension")

        output_info.precision = "FP32"


        # --------------------------- Performing inference ----------------------------------------------------
        log.info("Loading model to the device")
        exec_net = ie.load_network(network=net, device_name=DEVICE)
        log.info("Creating infer request and starting inference")
        res = exec_net.infer(inputs=data)



        # --------------------------- Read and postprocess output ---------------------------------------------
        log.info("Processing output blobs")
        res = res[out_blob]
        boxes, classes = {}, {}
        data = res[0][0]
        for number, proposal in enumerate(data):
            if proposal[2] > 0:
                imid = np.int(proposal[0])
                ih, iw = images_hw[imid]
                label = np.int(proposal[1])
                confidence = proposal[2]
                xmin = np.int(iw * proposal[3])
                ymin = np.int(ih * proposal[4])
                xmax = np.int(iw * proposal[5])
                ymax = np.int(ih * proposal[6])
                print("[{},{}] element, prob = {:.6}    ({},{})-({},{}) batch id : {}" \
                    .format(number, label, confidence, xmin, ymin, xmax, ymax, imid), end="")
                if proposal[2] > 0.5:
                    if not imid in boxes.keys():
                        boxes[imid] = []
                    boxes[imid].append([xmin, ymin, xmax, ymax])
                    if not imid in classes.keys():
                        classes[imid] = []
                    classes[imid].append(label)
                else:
                    print()

        for imid in classes:
            tmp_image = cv2.imread(args.input[imid])
            for box in boxes[imid]:
                cv2.rectangle(tmp_image, (box[0], box[1]), (box[2], box[3]), (232, 35, 244), 2)
            cv2.imwrite("out.bmp", tmp_image)
            log.info("Image out.bmp created!")